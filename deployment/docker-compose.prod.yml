version: '3.8'

services:
  # Production PostgreSQL with backup
  postgres:
    image: postgres:15-alpine
    container_name: eeg_postgres_prod
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./backups:/backups
    restart: unless-stopped
    command: >
      postgres
      -c shared_preload_libraries=pg_stat_statements
      -c pg_stat_statements.track=all
      -c max_connections=100
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
    networks:
      - eeg_network

  # Production Redis with persistence
  redis:
    image: redis:7-alpine
    container_name: eeg_redis_prod
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_prod_data:/data
    restart: unless-stopped
    networks:
      - eeg_network

  # Production API with Gunicorn
  api:
    build:
      context: ../backend
      dockerfile: Dockerfile.prod
    container_name: eeg_api_prod
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY}
      - SENDGRID_API_KEY=${SENDGRID_API_KEY}
      - SENTRY_DSN=${SENTRY_DSN}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET=${S3_BUCKET}
    volumes:
      - eeg_uploads_prod:/app/uploads
      - eeg_models_prod:/app/ml_models/saved_models
    restart: unless-stopped
    depends_on:
      - postgres
      - redis
    networks:
      - eeg_network

  # Production Celery Worker with autoscaling
  celery-worker:
    build:
      context: ../backend
      dockerfile: Dockerfile.prod
    command: >
      celery -A app.tasks.celery_tasks worker
      --loglevel=warning
      --concurrency=4
      --autoscale=8,2
      --max-tasks-per-child=1000
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SENTRY_DSN=${SENTRY_DSN}
    volumes:
      - eeg_uploads_prod:/app/uploads
      - eeg_models_prod:/app/ml_models/saved_models
    restart: unless-stopped
    depends_on:
      - postgres
      - redis
    networks:
      - eeg_network

  # Celery Beat for scheduled tasks
  celery-beat:
    build:
      context: ../backend
      dockerfile: Dockerfile.prod
    command: celery -A app.tasks.celery_tasks beat --loglevel=warning
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    volumes:
      - celery_beat_prod:/app/celerybeat-schedule
    restart: unless-stopped
    depends_on:
      - postgres
      - redis
    networks:
      - eeg_network

  # Nginx with SSL
  nginx:
    image: nginx:alpine
    container_name: eeg_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - ./logs:/var/log/nginx
    restart: unless-stopped
    depends_on:
      - api
    networks:
      - eeg_network

volumes:
  postgres_prod_data:
  redis_prod_data:
  eeg_uploads_prod:
  eeg_models_prod:
  celery_beat_prod:

networks:
  eeg_network:
    driver: bridge